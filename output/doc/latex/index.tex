\subsection*{Introduction}

Nassim Nicholas Taleb has recently released a paper entitled {\itshape How much data do you need? An operational metric for fat-\/tailedness}. to appear in the International Journal of Forecasting. The paper focuses on the preasymptotic behavior of the sum of independent identically distributed random variables that are governed by various fat-\/tailed distributions. He introduces a metric labeled \char`\"{}kappa\char`\"{} that\textquotesingle{}s related to the growth rate of the mean absolute deviation (M\+AD) as the number of summands increases. Kappa is defined by the following formula.

kappa(n0,n) = 2-\/ (log(n)-\/log(n0))/(log(M\+A\+D(n) -\/ M\+A\+D(n0))

Normally distributed variables have a kappa of zero. Thus the extent to which kappa is in excess of zero measures the \char`\"{}fat-\/tailedness\char`\"{}.

\subsection*{Purpose}

Taleb analyzes a number of distributions to estimate their kappa. He gives explicit formulae for kappa(1,2), which he was able to derive analytically, but he also includes tables of kappa(1,30) and kappa(1,100) for two distributions, namely the Pareto distribution and Student\textquotesingle{}s t distribution. This package is my effort to replicate those tables and perhaps add others for the other distributions. It\textquotesingle{}s a work in progress, as there are some items that I can\textquotesingle{}t closely replicate. However, none of the differences are large enough to call into question Taleb\textquotesingle{}s results.

\subsection*{What\textquotesingle{}s included}

I\textquotesingle{}ve experimented with three algorithms implemented in C++, one of which relies on monte carlo simulations, a second, which relies on the use of the discrete fourier transform of the characteristic function of the convolution of the distribution functions, and finally one that takes advantage of an integral representation of the M\+AD given the derivative of characteristic function of the underlying distribution.

The package includes several files developed for this project\+:


\begin{DoxyItemize}
\item convolution\+\_\+test.\+cpp. The main program to nun the convolution test, which will be retired in the next iteration. The pinelis\+\_\+taleb integral is vastly superior in terms of speed and accuracy.
\item \mbox{\hyperlink{monte__carlo__test_8cpp}{monte\+\_\+carlo\+\_\+test.\+cpp}}. The main program to run the monte carlo test. It\textquotesingle{}s bullet-\/proof but so slow that it\textquotesingle{}s hard to obtain the required accuracy in a reasonable time frame even using multi-\/threading.
\item \mbox{\hyperlink{pinelis__taleb__test_8cpp}{pinelis\+\_\+taleb\+\_\+test.\+cpp}}. The main program implementing the integral representation of M\+AD. This is my current method of choice.
\item \mbox{\hyperlink{pareto__distribution_8h}{pareto\+\_\+distribution.\+h}}. Contains a class for the pareto distribution, modeled on the classes in boost\+::random and including items normally computed in boost\+::math\+::statistical\+\_\+distributions
\item \mbox{\hyperlink{student__t__distribution_8h}{student\+\_\+t\+\_\+distribution.\+h}}. Similar to pareto but starts as a derived class from boost\+::random\+::student\+\_\+t\+\_\+distribution
\item \mbox{\hyperlink{exponential__distribution_8h}{exponential\+\_\+distribution.\+h}}. A derived class from boost\+::random\+::exponential\+\_\+distribution
\item \mbox{\hyperlink{lognormal__distribution_8h}{lognormal\+\_\+distribution.\+h}}. A derived class from boost\+::random\+::lognormal\+\_\+distribution. The class implementing the distribution includes several versions of the calculation of the characteristic function\+: some based on numerical integration from the definition, one based on a asymptotic series for small angular frequency and one based on a approximation using Lambert W functions.
\end{DoxyItemize}

In addition, i\textquotesingle{}ve included the apparatus I developed for adaptive integration, which seems to work much better that the Boost version that was originally used. The code is spread through the following files\+:


\begin{DoxyItemize}
\item adaptive\+\_\+integration.\+h. The file that defines the interface to the adaptive integration routines.
\item adaptive\+\_\+integration\+\_\+impl.\+h. Most of the actual implementation.
\item gauss\+\_\+kronrad.\+h. Interface to the functions used to calculate the nodes and weights for the integration.
\item gauss\+\_\+kronrod\+\_\+impl.\+h. The implementing code for gauss\+\_\+kronrod.
\item myfloat.\+h. Some basic definitions allowing various types of multi-\/precision numbers. Multiprecision is not used in the current implementation of how\+\_\+much\+\_\+data.
\end{DoxyItemize}

Finally included is a test program.


\begin{DoxyItemize}
\item lognormal\+\_\+test.\+cpp. A program to test the various versions of the calculation of the characteristic function. .
\end{DoxyItemize}

In order to improve portability, a meson.\+build file is included, which allows an easy port to other systems once the needed packages are installed.

\subsubsection*{Update Feb. 15, 2019}

I noticed that Taleb covered the same topic in N. N. Taleb,\href{https://www.academia.edu/37221402/THE_STATISTICAL_CONSEQUENCES_OF_FAT_TAILS_TECHNICAL_INCERTO_COLLECTION_?auto=download}{\tt Statistical Consequences of Fat Tails}. The procedure outlined in Section 6.\+5 of that monograph using results of Pinelis is of general applicability and is incorporated into pinelis\+\_\+taleb\+\_\+test.

\subsection*{Further Documentation}

The code has been documented using the doxygen system. The result can be accessed in the doc subdirectory of the output directory. The html version is accessed through html/index.\+html

\subsection*{Observations}

So far my results are close to Taleb\textquotesingle{}s. As Taleb mentions in his paper such distributions require huge amounts of data to produce reasonable estimates of the M\+AD and this fact is mirrored in the number of monte carlo runs or in the size the arrays used in the fast fourier transform. I\textquotesingle{}m pushing the limit of my computer\textquotesingle{}s capability for the cases where alpha = 1.\+25 or alpha = 1.\+5. The convolution is limited by the size of available memory and the monte carlo approach is limited by the amount of time and the number of processors available. The pinelis\+\_\+taleb integral bypasses most of these problems, but it requires a very accurate calculation of the characteristic function and its derivative and some ingenuity in choosing the right contour for integration.

I\textquotesingle{}ve experimented with other measures of scale, such as the 95\% confidence interval spread, for which the amount of computation needed is much more modest, but these results may not be relevant if M\+AD is the measure which best characterizes the uncertainty.

\subsubsection*{Relationship with the Statble Distribution}

Almost all of the distributions modeled have an associated stable distribution that is asymptotically equivalent to the modeled distribution. The kappa for stable distributions is always 2 -\/ alpha. However, in most cases the M\+AD for the associated stable distribution is significantly different from the M\+AD for the modelled distribution and the divergence of kappa from 2 -\/ alpha is associated with the rate of convergence of the M\+AD to the M\+AD of the associated stable distribution.

\subsubsection*{Lognormal Distribution}

As Taleb mentions in his paper, the lognormal distribution is a well behaved thin tail distriubtion for small sigma, but becomes a fat-\/tailed distribution for sigmas much in excess of one. The weakest part of the calculation here is associated with the large sigma runs of the for the convolution test of the lognormal distribution. These have three widely divergent scales associated with them. For instance, when mu=0 and sigma=5, the mode is about 1.\+4e-\/11, the mean and M\+AD are about 2.\+7e+5 and the stardard deviation is about 7.\+2e+10. The M\+AD for the normal distribution is sqrt(2/pi) times it\textquotesingle{}s standard deviation and therefore the the M\+AD normallized by n$^\wedge$.5 must go from 2.\+7e+5 to 5.\+7e+10 to reach it\textquotesingle{}s asymptotic state.

\subsection*{To Do}


\begin{DoxyItemize}
\item Implement the normal with switching variance distribution. This is the one that Taleb uses demonstrate the possibility of negative kappa.
\end{DoxyItemize}

\subsection*{Acknowledgements}


\begin{DoxyEnumerate}
\item The package makes heavy use of the Boost C++ headers available at \href{http://www.boost.org}{\tt boost}.
\item The package uses the Eigen headers for the purpose of wrapping the fast fourier transform code and holding the large arrays that are used by the fft. These are available at \href{http://www.eigen.tuxfamily.org}{\tt Eigen}.
\item As distributed the Eigen header wraps the fftw3 available at \href{http://fftw.org}{\tt fftw}. The fftw uses a G\+PL, so if you want a less restrictive license you should delete the line \#define E\+I\+G\+E\+N\+\_\+\+F\+F\+T\+W\+\_\+\+D\+E\+F\+A\+U\+LT at the beginning of convolution\+\_\+test.\+cpp, which will revert to the kissfft. Warning\+: kissfft uses much more memory and causes a severe slow down on my machine for the larger arrays because of swapping activiity.
\item One of the calculations of the characteristic function for the lognormal distribution uses Lambert W functions. I\textquotesingle{}ve used the C++ code for the complex Lambert W function from \href{https://sites.google.com/site/istvanmezo81/others}{\tt Istvan Mezo\textquotesingle{}s web page}.
\item The routines in the adaptive\+\_\+integration routine started out life as machine C++ translations of Fortran routines in Q\+U\+A\+D\+P\+A\+CK, which is part of S\+L\+A\+T\+EC and therefore in the public domain (\href{http://en.wikipedia.org/wiki/QUADPACK}{\tt http\+://en.\+wikipedia.\+org/wiki/\+Q\+U\+A\+D\+P\+A\+CK}). The routines were then heavily modified to take advantage of the C++ language.
\item One of the modifications made to Q\+U\+A\+D\+P\+A\+CK is the addition of the ability to calculate the nodes and weights for the Gauss Kronrod integration on the fly. For this purpose Dirk Laurie\textquotesingle{}s method is used \href{http://dip.sun.ac.za/~laurie/papers/kronrod/kronrod.ps}{\tt kronrod.\+ps}. The routines used here are C++ translations of Dirk Laurie\textquotesingle{}s M\+A\+T\+L\+AB code, which is included in Walter Gautschi\textquotesingle{}s O\+PQ suite \href{https://www.cs.purdue.edu/archives/2002/wxg/codes/OPQ.html}{\tt O\+PQ}.
\end{DoxyEnumerate}

\subsection*{License}

The code included here is covered the the M\+IT license. 